## [How to Construct Deep Recurrent Neural Networks](https://arxiv.org/abs/1312.6026)
Yoshua Bengio et al., Submitted on 20 Dec 2013

TLDR; The depth of an RNN is characterized by its input-to-hidden function, hidden-to-hidden transition and hidden-to-output function.

### Key Points
* Propose two novel architectures of a deep RNN which are orthogonal to an earlier attempt of stacking multiple recurrent layers to build a deep RNN (Schmidhuber, 1992; El Hihi and Bengio, 1996).
* 

### Notes / Questions

### Results
* Evaluated on the tasks of polyphonic music prediction and language modeling

